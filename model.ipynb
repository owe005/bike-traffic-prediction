{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **INF161 - Bike Traffic Prediction Modelling**\n",
    "### *Ole Kristian Westby | owe009@uib.no | H23*\n",
    "\n",
    "In this notebook, I will go through modelling and prediction for this project. My starting plan here is grabbing the final dataframe which was made for the previous deadline. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datotid</th>\n",
       "      <th>Trafikkmengde</th>\n",
       "      <th>Globalstraling</th>\n",
       "      <th>Solskinstid</th>\n",
       "      <th>Lufttemperatur</th>\n",
       "      <th>Vindstyrke</th>\n",
       "      <th>Vindkast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-07-16 15:00:00</td>\n",
       "      <td>50</td>\n",
       "      <td>504.400000</td>\n",
       "      <td>7.233333</td>\n",
       "      <td>13.900000</td>\n",
       "      <td>4.083333</td>\n",
       "      <td>6.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-07-16 16:00:00</td>\n",
       "      <td>101</td>\n",
       "      <td>432.833333</td>\n",
       "      <td>8.116667</td>\n",
       "      <td>13.733333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>7.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-07-16 17:00:00</td>\n",
       "      <td>79</td>\n",
       "      <td>378.400000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>13.866667</td>\n",
       "      <td>3.933333</td>\n",
       "      <td>6.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-07-16 18:00:00</td>\n",
       "      <td>56</td>\n",
       "      <td>212.583333</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>13.216667</td>\n",
       "      <td>4.233333</td>\n",
       "      <td>7.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-07-16 19:00:00</td>\n",
       "      <td>45</td>\n",
       "      <td>79.750000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>12.683333</td>\n",
       "      <td>2.950000</td>\n",
       "      <td>5.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Datotid  Trafikkmengde  Globalstraling  Solskinstid  \\\n",
       "0  2015-07-16 15:00:00             50      504.400000     7.233333   \n",
       "1  2015-07-16 16:00:00            101      432.833333     8.116667   \n",
       "2  2015-07-16 17:00:00             79      378.400000    10.000000   \n",
       "3  2015-07-16 18:00:00             56      212.583333    10.000000   \n",
       "4  2015-07-16 19:00:00             45       79.750000    10.000000   \n",
       "\n",
       "   Lufttemperatur  Vindstyrke  Vindkast  \n",
       "0       13.900000    4.083333      6.70  \n",
       "1       13.733333    4.333333      7.20  \n",
       "2       13.866667    3.933333      6.55  \n",
       "3       13.216667    4.233333      7.15  \n",
       "4       12.683333    2.950000      5.45  "
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dir = 'ready_data/ready_data.csv'\n",
    "\n",
    "# Load data into a dataframe\n",
    "df = pd.read_csv(dir)\n",
    "\n",
    "# Look at first rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check for missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Datotid             0\n",
       "Trafikkmengde       0\n",
       "Globalstraling    403\n",
       "Solskinstid       403\n",
       "Lufttemperatur    403\n",
       "Vindstyrke        403\n",
       "Vindkast          403\n",
       "dtype: int64"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing data\n",
    "missing_data = df.isnull().sum()\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll convert the \"Datotid\" column to datetime format, and extract month, day and hour from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datotid</th>\n",
       "      <th>Trafikkmengde</th>\n",
       "      <th>Globalstraling</th>\n",
       "      <th>Solskinstid</th>\n",
       "      <th>Lufttemperatur</th>\n",
       "      <th>Vindstyrke</th>\n",
       "      <th>Vindkast</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-07-16 15:00:00</td>\n",
       "      <td>50</td>\n",
       "      <td>504.400000</td>\n",
       "      <td>7.233333</td>\n",
       "      <td>13.900000</td>\n",
       "      <td>4.083333</td>\n",
       "      <td>6.70</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-07-16 16:00:00</td>\n",
       "      <td>101</td>\n",
       "      <td>432.833333</td>\n",
       "      <td>8.116667</td>\n",
       "      <td>13.733333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>7.20</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-07-16 17:00:00</td>\n",
       "      <td>79</td>\n",
       "      <td>378.400000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>13.866667</td>\n",
       "      <td>3.933333</td>\n",
       "      <td>6.55</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-07-16 18:00:00</td>\n",
       "      <td>56</td>\n",
       "      <td>212.583333</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>13.216667</td>\n",
       "      <td>4.233333</td>\n",
       "      <td>7.15</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-07-16 19:00:00</td>\n",
       "      <td>45</td>\n",
       "      <td>79.750000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>12.683333</td>\n",
       "      <td>2.950000</td>\n",
       "      <td>5.45</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Datotid  Trafikkmengde  Globalstraling  Solskinstid  \\\n",
       "0 2015-07-16 15:00:00             50      504.400000     7.233333   \n",
       "1 2015-07-16 16:00:00            101      432.833333     8.116667   \n",
       "2 2015-07-16 17:00:00             79      378.400000    10.000000   \n",
       "3 2015-07-16 18:00:00             56      212.583333    10.000000   \n",
       "4 2015-07-16 19:00:00             45       79.750000    10.000000   \n",
       "\n",
       "   Lufttemperatur  Vindstyrke  Vindkast  Month  DayOfWeek  Hour  \n",
       "0       13.900000    4.083333      6.70      7          3    15  \n",
       "1       13.733333    4.333333      7.20      7          3    16  \n",
       "2       13.866667    3.933333      6.55      7          3    17  \n",
       "3       13.216667    4.233333      7.15      7          3    18  \n",
       "4       12.683333    2.950000      5.45      7          3    19  "
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Datetime format\n",
    "df['Datotid'] = pd.to_datetime(df['Datotid'])\n",
    "\n",
    "# Extracting time-related stuff\n",
    "df['Month'] = df['Datotid'].dt.month\n",
    "df['DayOfWeek'] = df['Datotid'].dt.dayofweek # Monday: 0, Tuesday: 1, ... , Sunday: 6.\n",
    "df['Hour'] = df['Datotid'].dt.hour\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, regarding the missing values in the dataframe, we're gonna fix this by imputing them with the median because it's less sensitive to outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Datotid           0\n",
       "Trafikkmengde     0\n",
       "Globalstraling    0\n",
       "Solskinstid       0\n",
       "Lufttemperatur    0\n",
       "Vindstyrke        0\n",
       "Vindkast          0\n",
       "Month             0\n",
       "DayOfWeek         0\n",
       "Hour              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Impute with median\n",
    "for col in missing_data.index[missing_data > 0]:\n",
    "    df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "# Now we can check again\n",
    "missing_data = (df.isnull().sum())\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it has now been fixed. Now that our data is clean, we can start with data splitting. We will first need to import an additional library for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32680, 8), (32681, 8))"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(columns=['Datotid', 'Trafikkmengde'])\n",
    "y = df['Trafikkmengde']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.5, random_state=1)\n",
    "\n",
    "X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has now been sucessfully split into a training set, and a validation set. The training set contains 32,680 samples and the validation set contains 32,681 samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to select a model, and we'll need to import numpy, as well as the models and MSE. Let's try Linear Regression as our first model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.68697933176709"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the model and train it\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "lr_predict = lr.predict(X_val)\n",
    "\n",
    "lr_rmse = np.sqrt(mean_squared_error(y_val, lr_predict))\n",
    "\n",
    "lr_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RMSE for this model is 61.6793 approx. Before we continue checking different models, I wish to stop here and think a bit. Is ~61.6793 a good RMSE here? I think in order to evaluate this, we need to check how many cycle on average each day. Let's check this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    65361.000000\n",
       "mean        50.379905\n",
       "std         69.782243\n",
       "min          0.000000\n",
       "25%          5.000000\n",
       "50%         25.000000\n",
       "75%         64.000000\n",
       "max        608.000000\n",
       "Name: Trafikkmengde, dtype: float64"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cycle_stats = df['Trafikkmengde'].describe()\n",
    "cycle_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given this, it is clear that an RMSE of 61,67 is pretty high, especially since the 75th percentile is 64 cycles. On average we're gonna be really off with this. This model won't do, we need to explore some more.. We can try the Lasso Regression model from the lab works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.693154529589826"
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Initialize the model and train it\n",
    "lasso = Lasso(alpha=0.1, random_state=1)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Predict on val set\n",
    "lasso_predict = lasso.predict(X_val)\n",
    "\n",
    "# RMSE\n",
    "lasso_rmse = np.sqrt(mean_squared_error(y_val, lasso_predict))\n",
    "lasso_rmse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm.. that's even worse (not that much more worse!). So far the Linear Regression model is winning, but there has to be a better one.. How about Random Forest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.336702706600718"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize the model and train it\n",
    "rf = RandomForestRegressor(n_estimators=10, random_state=1) # With 100 estimators, the RMSE is 26.1455 instead, but it took a minute to run. # 1000: 25,89\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on val set\n",
    "rf_predict = rf.predict(X_val)\n",
    "\n",
    "# RMSE\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_val, rf_predict))\n",
    "rf_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woah! That's a big improvement. Definitely the best model so far with RMSE ~27.01 (26.1455 with 100 estimators, 25.89 with 1000 estimators (took 11 minutes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53.0983290926551"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Initialize the model and train it\n",
    "gb = GradientBoostingRegressor(n_estimators=10, random_state=1)\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "# Predict on val set\n",
    "gb_predict = gb.predict(X_val)\n",
    "\n",
    "# RMSE\n",
    "gb_rmse = np.sqrt(mean_squared_error(y_val, gb_predict))\n",
    "gb_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, not better. Okay, out of the three models we tested so far, RandomForest is winning. I'll try some more.. ps: in the final deadline I will probably make adjustments so it will check all models at once for the best one instead of individually like this, this is just for visualization and thought-descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.754404052183446"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# Initialize the model and train it\n",
    "elastic_net = ElasticNet(alpha=1, random_state=1)\n",
    "elastic_net.fit(X_train, y_train)\n",
    "\n",
    "# Predict on val set\n",
    "y_predict = elastic_net.predict(X_val)\n",
    "\n",
    "# RMSE\n",
    "en_rmse = np.sqrt(mean_squared_error(y_val, y_predict))\n",
    "en_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a different type of model, KNeighborsRegressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.66251270465994"
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Initialize the model and train it\n",
    "kn = KNeighborsRegressor(n_neighbors=10)\n",
    "kn.fit(X_train, y_train)\n",
    "\n",
    "# Predict on val set\n",
    "y_predict = kn.predict(X_val)\n",
    "\n",
    "# RMSE\n",
    "kn_rmse = np.sqrt(mean_squared_error(y_val, y_predict))\n",
    "kn_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After trying all of these models, I think I will stick with RandomForestRegressor. Let's now use GridSearchCV to find the optimal hyperparameters. This will take about 25-30 minutes on my computer to run. I will probably comment this out, alternatively leave it out when running the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nfrom sklearn.model_selection import GridSearchCV\\n\\n# Define parameter grid\\nparam_grid = {\\n    'n_estimators': [10, 50, 100, 200],\\n    'max_depth': [None, 10, 20, 30],\\n    'min_samples_split': [2, 5, 10],\\n    'min_samples_leaf': [1, 2, 4]\\n}\\n\\ngrid_search = GridSearchCV(estimator=rf, \\n                           param_grid=param_grid, \\n                           cv=3, \\n                           n_jobs=-1, \\n                           verbose=2, \\n                           scoring='neg_mean_squared_error')\\n\\ngrid_search.fit(X_train, y_train)\\n\\nbest_params = grid_search.best_params_\\n\\nbest_rf = grid_search.best_estimator_\\n\\nrf_predict = best_rf.predict(X_val)\\n\\nrf_rmse = np.sqrt(mean_squared_error(y_val, rf_predict))\\n\\nrf_rmse\\nbest_rf\\n\\n\""
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf, \n",
    "                           param_grid=param_grid, \n",
    "                           cv=3, \n",
    "                           n_jobs=-1, \n",
    "                           verbose=2, \n",
    "                           scoring='neg_mean_squared_error')\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "rf_predict = best_rf.predict(X_val)\n",
    "\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_val, rf_predict))\n",
    "\n",
    "rf_rmse\n",
    "best_rf\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV gives the best hyperparameters as: (min_samples_leaf=4, n_estimators=200, random_state=1). This took 35 minutes for me to run, so I am embedding a picture proof so nobody has to run this again. RMSE is around 25.8~\n",
    "\n",
    "![alt text](gridsearchd.png \"GridSearch\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
