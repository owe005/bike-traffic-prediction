{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **INF161 - Bike Traffic Prediction Project**\n",
    "### *Ole Kristian Westby | owe009@uib.no | H23*\n",
    "\n",
    "This project uses data from Statens vegvesen and Geofysisk institutt. The goal is to create a model that can predict the volume of bikers at a given time over Nygårdsbroen. I'll need to prepare the data so I'm left with the data I deem valuable to perform this task. That's what this Jupyter notebook is for. I'll also be explaining my steps throughout the book. At the end, we'll have some juicy, ready data that we'll use to insert into /ready_data/ ready for the model to work on.\n",
    "\n",
    "I recognize that throughout the years there has been some times where people might have used the bikes more/less frequently because of certain factors. I will keep a list that I will update continuously as I find them.\n",
    "- Covid-19 likely kept more people home, especially in peak times. Less people using bicycles to get to work as they had work from home. Only interested in peak covid-19 times though. \n",
    "- 2017 UCI Road World Championships. I've checked the routes and don't see that any bikes passed Nygårdsbroen but I will look closer at the data later.\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Let's start by importing some libraries.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **We'll handle the traffic data first.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Dato    Tid  Solskinstid  Lufttemperatur  Vindstyrke  Vindkast\n",
      "0       2010-01-01  00:00          0.0            -4.6         1.1       NaN\n",
      "1       2010-01-01  00:10          0.0            -4.1         1.6       NaN\n",
      "2       2010-01-01  00:20          0.0            -3.5         1.3       NaN\n",
      "3       2010-01-01  00:30          0.0            -4.1         0.7       NaN\n",
      "4       2010-01-01  00:40          0.0            -4.4         0.8       NaN\n",
      "...            ...    ...          ...             ...         ...       ...\n",
      "709216  2023-06-30  23:10          0.0            13.7         2.3       3.6\n",
      "709217  2023-06-30  23:20          0.0            13.6         1.9       3.3\n",
      "709218  2023-06-30  23:30          0.0            13.6         1.7       3.0\n",
      "709219  2023-06-30  23:40          0.0            13.6         1.9       3.3\n",
      "709220  2023-06-30  23:50          0.0            13.5         1.9       3.0\n",
      "\n",
      "[709221 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "dir_weather = \"raw_data/weather_data/\"\n",
    "\n",
    "files = [f for f in os.listdir(dir_weather) if f.endswith('.csv')]\n",
    "\n",
    "# Interesting columns\n",
    "columns = [\"Dato\", \"Tid\", \"Solskinstid\", \"Lufttemperatur\", \"Vindstyrke\", \"Vindkast\"]\n",
    "\n",
    "dfs = []\n",
    "for file in files:\n",
    "\n",
    "    file_path = os.path.join(dir_weather, file)\n",
    "\n",
    "    df = pd.read_csv(file_path, usecols=columns)\n",
    "\n",
    "    dfs.append(df)\n",
    "\n",
    "merged_df = pd.concat(dfs, ignore_index=True)\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Now we've created one big dataframe containing all interesting weather data from 2010 to 2023. However, the traffic data only goes from 2015-2023, and so I want to clear the dataset for any weather data before that. The model is going to get slightly less accurate with less data, but I think there's enough data already with 2015-2023 to do this anyways. It makes it simpler as well. I won't remove the data from the raw_data folder because I still recognize it there, and I want to see the different predictions based on it being included or not, but for now I won't focus on it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Dato    Tid  Solskinstid  Lufttemperatur  Vindstyrke  Vindkast\n",
      "262467 2015-01-01  00:00          0.0             6.6         4.2       NaN\n",
      "262468 2015-01-01  00:10          0.0             6.6         4.0       NaN\n",
      "262469 2015-01-01  00:20          0.0             6.6         3.1       NaN\n",
      "262470 2015-01-01  00:30          0.0             6.6         3.7       NaN\n",
      "262471 2015-01-01  00:40          0.0             6.7         2.9       NaN\n",
      "...           ...    ...          ...             ...         ...       ...\n",
      "709216 2023-06-30  23:10          0.0            13.7         2.3       3.6\n",
      "709217 2023-06-30  23:20          0.0            13.6         1.9       3.3\n",
      "709218 2023-06-30  23:30          0.0            13.6         1.7       3.0\n",
      "709219 2023-06-30  23:40          0.0            13.6         1.9       3.3\n",
      "709220 2023-06-30  23:50          0.0            13.5         1.9       3.0\n",
      "\n",
      "[446754 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "merged_df[\"Dato\"] = pd.to_datetime(merged_df[\"Dato\"])\n",
    "\n",
    "merged_df = merged_df[merged_df[\"Dato\"].dt.year >= 2015]\n",
    "\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **As we see in the beginning of the merged dataframe, we see some data missing in 2015-01-01 for Vindkast. I want clean, full data and who knows how many rows are missing data in one or more columns. Let's find out.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3786\n"
     ]
    }
   ],
   "source": [
    "rows_missing_data = merged_df[merged_df.isna().any(axis=1)].shape[0]\n",
    "print(rows_missing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **As we can see, there are 3786 rows that are missing some data. 3786 is only 0,84% of the merged dataframe. I think we can afford to get rid of that.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Dato    Tid  Solskinstid  Lufttemperatur  Vindstyrke  Vindkast\n",
      "0      2015-01-08  15:30          0.0             4.4         1.3       3.6\n",
      "1      2015-01-08  15:40          0.0             4.7         1.6       2.7\n",
      "2      2015-01-08  15:50          0.0             4.5         1.9       2.7\n",
      "3      2015-01-08  16:00          0.0             4.2         3.2       5.4\n",
      "4      2015-01-08  16:10          0.0             4.5         2.8       4.5\n",
      "...           ...    ...          ...             ...         ...       ...\n",
      "442963 2023-06-30  23:10          0.0            13.7         2.3       3.6\n",
      "442964 2023-06-30  23:20          0.0            13.6         1.9       3.3\n",
      "442965 2023-06-30  23:30          0.0            13.6         1.7       3.0\n",
      "442966 2023-06-30  23:40          0.0            13.6         1.9       3.3\n",
      "442967 2023-06-30  23:50          0.0            13.5         1.9       3.0\n",
      "\n",
      "[442968 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "merged_df.dropna(inplace=True)\n",
    "\n",
    "merged_df = merged_df.reset_index(drop=True)\n",
    "\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **The next thing I want to do is combine the columns \"Dato\" and \"Tid\" to get a single datetime column. This will be useful later.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Solskinstid  Lufttemperatur  Vindstyrke  Vindkast             Datotid\n",
      "0               0.0             4.4         1.3       3.6 2015-01-08 15:30:00\n",
      "1               0.0             4.7         1.6       2.7 2015-01-08 15:40:00\n",
      "2               0.0             4.5         1.9       2.7 2015-01-08 15:50:00\n",
      "3               0.0             4.2         3.2       5.4 2015-01-08 16:00:00\n",
      "4               0.0             4.5         2.8       4.5 2015-01-08 16:10:00\n",
      "...             ...             ...         ...       ...                 ...\n",
      "442963          0.0            13.7         2.3       3.6 2023-06-30 23:10:00\n",
      "442964          0.0            13.6         1.9       3.3 2023-06-30 23:20:00\n",
      "442965          0.0            13.6         1.7       3.0 2023-06-30 23:30:00\n",
      "442966          0.0            13.6         1.9       3.3 2023-06-30 23:40:00\n",
      "442967          0.0            13.5         1.9       3.0 2023-06-30 23:50:00\n",
      "\n",
      "[442968 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "merged_df[\"Dato\"] = merged_df[\"Dato\"].astype(str)\n",
    "merged_df[\"Tid\"] = merged_df[\"Tid\"].astype(str)\n",
    "\n",
    "merged_df[\"Datotid\"] = merged_df[\"Dato\"] + \" \" + merged_df[\"Tid\"]\n",
    "\n",
    "merged_df[\"Datotid\"] = pd.to_datetime(merged_df[\"Datotid\"])\n",
    "\n",
    "merged_df.drop([\"Dato\", \"Tid\"], axis=1, inplace=True)\n",
    "\n",
    "print(merged_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
